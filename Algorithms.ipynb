{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49459e9b-99f7-41f6-a659-9fbc7f07832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I\\AppData\\Local\\Temp\\ipykernel_13604\\2987393687.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286c3830-5d05-4106-906a-a7a3386efbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier_indices(df, features):\n",
    "    outlier_indices = []\n",
    "\n",
    "    for c in features:\n",
    "        Q1 = df[c].quantile(0.25)\n",
    "        Q3 = df[c].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        outlier_step = 1.5 * IQR\n",
    "\n",
    "        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "\n",
    "    outlier_indices = list(set(outlier_indices))\n",
    "    return outlier_indices\n",
    "\n",
    "def remove_outliers(df, features):\n",
    "    outlier_indices = get_outlier_indices(df, features)\n",
    "    df_cleaned = df.drop(outlier_indices)\n",
    "    df_cleaned.reset_index(drop=True, inplace=True)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10d3551-3b75-4904-8a01-82ab51a1bb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korisnik\\AppData\\Local\\Temp\\ipykernel_8740\\1441606978.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.flight_class = df.flight_class.replace({'Economy' : 1,'Business' :2})\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv('Clean_Dataset.csv')\n",
    "columns_to_drop = ['Unnamed: 0', 'flight']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "le = LabelEncoder()\n",
    "df.flight_class = df.flight_class.replace({'Economy' : 1,'Business' :2})\n",
    "df['airline'] = le.fit_transform(df['airline'])\n",
    "df['source_city'] = le.fit_transform(df['source_city'])\n",
    "df['destination_city'] = le.fit_transform(df['destination_city'])\n",
    "df['departure_time'] = le.fit_transform(df['departure_time'])\n",
    "df['arrival_time'] = le.fit_transform(df['arrival_time'])\n",
    "df['stops'] = le.fit_transform(df['stops'])\n",
    "# # One-hot encoding\n",
    "# columns_to_onehot = ['airline', 'source_city', 'destination_city', 'departure_time', 'arrival_time', 'stops']\n",
    "\n",
    "# ohe = OneHotEncoder(drop='first', sparse_output=False)\n",
    "# one_hot_encoded = ohe.fit_transform(df[columns_to_onehot])\n",
    "\n",
    "# df_encoded = pandas.DataFrame(one_hot_encoded, columns=ohe.get_feature_names_out(columns_to_onehot))\n",
    "# df = pandas.concat([df.drop(columns=columns_to_onehot), df_encoded], axis=1)\n",
    "df = remove_outliers(df, ['duration', 'price'])\n",
    "X = df.drop(columns='price')\n",
    "y = df.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "df_business = df[df['flight_class'] == 2]\n",
    "X_business = df_business.drop(columns='price')\n",
    "y_business = df_business.price\n",
    "X_train_business, X_test_business, y_train_business, y_test_business = train_test_split(X_business, y_business, test_size=0.20, random_state=0)\n",
    "\n",
    "df_economy = df[df['flight_class'] == 1]\n",
    "X_economy = df_economy.drop(columns='price')\n",
    "y_economy = df_economy.price\n",
    "X_train_economy, X_test_economy, y_train_economy, y_test_economy = train_test_split(X_economy, y_economy, test_size=0.20, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79ffe9-6518-45ae-848d-d7a15aac2826",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d6264f-bee2-488c-bf4c-5de8cdbcab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 48220128.129044436\n",
      "RMSE: 6944.071437495761\n",
      "MAE: 4635.282149073735\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X, y)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred_lr)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred_lr)\n",
    "print(\"MSE: \" + str(mse))\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "print(\"MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de42bb4-348e-4cd9-af48-e7aa25f5b122",
   "metadata": {},
   "source": [
    "## Linear regression for business class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746e645c-7b67-4081-afa2-a0e0da21bd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 94337423.44612947\n",
      "RMSE: 9712.745412401659\n",
      "MAE: 7376.578364521865\n"
     ]
    }
   ],
   "source": [
    "lr_business = LinearRegression().fit(X_business, y_business)\n",
    "y_pred_lr_business = lr_business.predict(X_test_business)\n",
    "mse_business = metrics.mean_squared_error(y_test_business, y_pred_lr_business)\n",
    "rmse_business = math.sqrt(mse_business)\n",
    "mae_business = metrics.mean_absolute_error(y_test_business, y_pred_lr_business)\n",
    "print(\"MSE: \" + str(mse_business))\n",
    "print(\"RMSE: \" + str(rmse_business))\n",
    "print(\"MAE: \" + str(mae_business))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9a02bb-b6fe-4faa-bea5-1e40990905b6",
   "metadata": {},
   "source": [
    "## Linear regression for economy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e015d7be-d3a0-4dab-93fe-b3c538bca242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 8168976.152494205\n",
      "RMSE: 2858.1420805296234\n",
      "MAE: 2065.8963861229067\n"
     ]
    }
   ],
   "source": [
    "lr_economy = LinearRegression().fit(X_economy, y_economy)\n",
    "y_pred_lr_economy = lr_economy.predict(X_test_economy)\n",
    "mse_economy = metrics.mean_squared_error(y_test_economy, y_pred_lr_economy)\n",
    "rmse_economy = math.sqrt(mse_economy)\n",
    "mae_economy = metrics.mean_absolute_error(y_test_economy, y_pred_lr_economy)\n",
    "print(\"MSE: \" + str(mse_economy))\n",
    "print(\"RMSE: \" + str(rmse_economy))\n",
    "print(\"MAE: \" + str(mae_economy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9ba1e-903e-40be-991c-0c75a00cdc2c",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856d3722-c9aa-4546-8801-5b8fa9f700c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 7311588.434043385\n",
      "RMSE: 2703.9949027399043\n",
      "MAE: 1070.847516833957\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#     'max_features': [2, 4, 6, 8],\n",
    "# }\n",
    "# rf = RandomForestRegressor(n_jobs=-1)\n",
    "# grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)\n",
    "final_rf = RandomForestRegressor(n_estimators=500, max_features=8, n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_rf = final_rf.predict(X_test)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred_rf)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c23da41-a44c-430f-99f0-262ff8df75ac",
   "metadata": {},
   "source": [
    "## Random forest for business class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b34a88da-4f4f-4f03-b328-8c9359f7684a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18960993.733425427\n",
      "RMSE: 4354.422319140098\n",
      "MAE: 2059.5050704621267\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#     'max_features': [2, 4, 6, 8],\n",
    "# }\n",
    "# rf = RandomForestRegressor(n_jobs=-1)\n",
    "# grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search.fit(X_train_business, y_train_business)\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)\n",
    "final_rf = RandomForestRegressor(n_estimators=500, max_features=8, n_jobs=-1).fit(X_train_business, y_train_business)\n",
    "y_pred_rf_business = final_rf.predict(X_test_business)\n",
    "mse = metrics.mean_squared_error(y_test_business, y_pred_rf_business)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_test_business, y_pred_rf_business)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df237c44-d016-4feb-9aa1-a27dbf4e3a3d",
   "metadata": {},
   "source": [
    "## Random forest for economy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "770dea93-69cd-4f26-9211-e03656f6c3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1908115.2719808498\n",
      "RMSE: 1381.3454571470706\n",
      "MAE: 614.64680957267\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#     'max_features': [2, 4, 6, 8],\n",
    "# }\n",
    "# rf = RandomForestRegressor(n_jobs=-1)\n",
    "# grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search.fit(X_train_economy, y_train_economy)\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)\n",
    "final_rf = RandomForestRegressor(n_estimators=500, max_features=8, n_jobs=-1).fit(X_train_economy, y_train_economy)\n",
    "y_pred_rf = final_rf.predict(X_test_economy)\n",
    "mse = metrics.mean_squared_error(y_test_economy, y_pred_rf)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_test_economy, y_pred_rf)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a6813-f086-48d2-9e52-6a356cdc3e6a",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c860936-85fc-4709-9774-de83afd1fb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5959/5959 [==============================] - 30s 5ms/step - loss: 127364008.0000 - mae: 6331.6567 - val_loss: 29978430.0000 - val_mae: 3390.8547\n",
      "Epoch 2/10\n",
      "5959/5959 [==============================] - 28s 5ms/step - loss: 27978258.0000 - mae: 3246.2256 - val_loss: 27967138.0000 - val_mae: 3203.2166\n",
      "Epoch 3/10\n",
      "5959/5959 [==============================] - 28s 5ms/step - loss: 26662324.0000 - mae: 3132.8635 - val_loss: 26969240.0000 - val_mae: 3137.2117\n",
      "Epoch 4/10\n",
      "5959/5959 [==============================] - 26s 4ms/step - loss: 25722842.0000 - mae: 3059.3945 - val_loss: 25885694.0000 - val_mae: 3060.2773\n",
      "Epoch 5/10\n",
      "5959/5959 [==============================] - 28s 5ms/step - loss: 24728002.0000 - mae: 2989.2683 - val_loss: 25157052.0000 - val_mae: 3026.9038\n",
      "Epoch 6/10\n",
      "5959/5959 [==============================] - 29s 5ms/step - loss: 23640984.0000 - mae: 2911.2534 - val_loss: 23561452.0000 - val_mae: 2882.3240\n",
      "Epoch 7/10\n",
      "5959/5959 [==============================] - 26s 4ms/step - loss: 22467488.0000 - mae: 2823.2078 - val_loss: 22390070.0000 - val_mae: 2802.6987\n",
      "Epoch 8/10\n",
      "5959/5959 [==============================] - 28s 5ms/step - loss: 21517838.0000 - mae: 2749.0139 - val_loss: 21466228.0000 - val_mae: 2723.6782\n",
      "Epoch 9/10\n",
      "5959/5959 [==============================] - 29s 5ms/step - loss: 20846230.0000 - mae: 2695.7048 - val_loss: 20913874.0000 - val_mae: 2682.5605\n",
      "Epoch 10/10\n",
      "5959/5959 [==============================] - 28s 5ms/step - loss: 20314680.0000 - mae: 2651.8604 - val_loss: 20418884.0000 - val_mae: 2645.7307\n",
      "1862/1862 [==============================] - 7s 4ms/step - loss: 19842606.0000 - mae: 2627.6348\n",
      "Test MAE: 2627.634765625\n",
      "1862/1862 [==============================] - 6s 3ms/step\n",
      "Test MSE: 19842597.290863883\n",
      "Test RMSE: 4454.503035228945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# param_grid = {\n",
    "#     'neurons1': [64, 128, 256],\n",
    "#     'neurons2': [32, 64, 128],\n",
    "#     'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search_result = grid_search.fit(X_train_scaled, y_train)\n",
    "# best_params = grid_search_result.best_params_\n",
    "# print(best_params)\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test MAE: {test_mae}')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print MSE and RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Test MSE: {mse}')\n",
    "print(f'Test RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22e686-f47d-4ea9-8f73-4c75d0096894",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron for business class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8603d45-bddf-4af6-aede-6307a41b0933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1863/1863 [==============================] - 8s 4ms/step - loss: 1193179520.0000 - mae: 27680.0195 - val_loss: 115625728.0000 - val_mae: 7895.0015\n",
      "Epoch 2/10\n",
      "1863/1863 [==============================] - 8s 4ms/step - loss: 107395840.0000 - mae: 7603.6787 - val_loss: 103257264.0000 - val_mae: 7423.5708\n",
      "Epoch 3/10\n",
      "1863/1863 [==============================] - 8s 4ms/step - loss: 98365656.0000 - mae: 7296.5811 - val_loss: 96111152.0000 - val_mae: 7218.2803\n",
      "Epoch 4/10\n",
      "1863/1863 [==============================] - 8s 4ms/step - loss: 93299048.0000 - mae: 7145.3037 - val_loss: 92351112.0000 - val_mae: 7103.8833\n",
      "Epoch 5/10\n",
      "1863/1863 [==============================] - 7s 4ms/step - loss: 90589248.0000 - mae: 7063.3931 - val_loss: 90315784.0000 - val_mae: 7049.2295\n",
      "Epoch 6/10\n",
      "1863/1863 [==============================] - 7s 4ms/step - loss: 89063208.0000 - mae: 7017.8257 - val_loss: 89305360.0000 - val_mae: 7003.2983\n",
      "Epoch 7/10\n",
      "1863/1863 [==============================] - 8s 4ms/step - loss: 88074192.0000 - mae: 6982.7876 - val_loss: 88331720.0000 - val_mae: 6981.2446\n",
      "Epoch 8/10\n",
      "1863/1863 [==============================] - 7s 4ms/step - loss: 87353832.0000 - mae: 6958.8896 - val_loss: 87928344.0000 - val_mae: 6972.7568\n",
      "Epoch 9/10\n",
      "1863/1863 [==============================] - 6s 3ms/step - loss: 86829536.0000 - mae: 6936.7705 - val_loss: 87152872.0000 - val_mae: 6954.0625\n",
      "Epoch 10/10\n",
      "1863/1863 [==============================] - 6s 3ms/step - loss: 86379176.0000 - mae: 6918.6118 - val_loss: 86807488.0000 - val_mae: 6929.5610\n",
      "583/583 [==============================] - 2s 3ms/step - loss: 85973664.0000 - mae: 6884.0337\n",
      "Test MAE: 6884.03369140625\n",
      "583/583 [==============================] - 2s 3ms/step\n",
      "Test MSE: 85973699.30518411\n",
      "Test RMSE: 9272.200348632687\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_business)\n",
    "X_test_scaled = scaler.transform(X_test_business)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# param_grid = {\n",
    "#     'neurons1': [64, 128, 256],\n",
    "#     'neurons2': [32, 64, 128],\n",
    "#     'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search_result = grid_search.fit(X_train_scaled, y_train_business)\n",
    "# best_params = grid_search_result.best_params_\n",
    "# print(best_params)\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(X_train_business.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.fit(X_train_scaled, y_train_business, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test_business)\n",
    "print(f'Test MAE: {test_mae}')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print MSE and RMSE\n",
    "mse = mean_squared_error(y_test_business, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Test MSE: {mse}')\n",
    "print(f'Test RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac5a16-3501-4525-930b-0d76dd982a4a",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron for economy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7588ff18-cb44-46a3-944e-ceda5e075bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 18s 4ms/step - loss: 11750851.0000 - mae: 2400.3306 - val_loss: 7071075.5000 - val_mae: 1889.7917\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 16s 4ms/step - loss: 6750533.0000 - mae: 1832.1425 - val_loss: 6525417.5000 - val_mae: 1801.9952\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 15s 4ms/step - loss: 6513139.5000 - mae: 1786.9182 - val_loss: 6377262.5000 - val_mae: 1764.9692\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 15s 4ms/step - loss: 6393164.0000 - mae: 1762.4928 - val_loss: 6269228.0000 - val_mae: 1742.4758\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 16s 4ms/step - loss: 6259447.5000 - mae: 1735.7793 - val_loss: 6115003.5000 - val_mae: 1721.2584\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 16s 4ms/step - loss: 6048398.5000 - mae: 1697.2136 - val_loss: 5856969.5000 - val_mae: 1668.3007\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 15s 4ms/step - loss: 5851500.5000 - mae: 1661.4518 - val_loss: 5713683.5000 - val_mae: 1650.1810\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 15s 4ms/step - loss: 5747729.0000 - mae: 1642.0916 - val_loss: 5702336.5000 - val_mae: 1662.6768\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 15s 4ms/step - loss: 5685271.5000 - mae: 1631.0051 - val_loss: 5595306.0000 - val_mae: 1630.2106\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 15s 4ms/step - loss: 5624232.5000 - mae: 1619.4371 - val_loss: 5536466.5000 - val_mae: 1624.6990\n",
      "1280/1280 [==============================] - 3s 3ms/step - loss: 5618100.5000 - mae: 1623.4858\n",
      "Test MAE: 1623.48583984375\n",
      "1280/1280 [==============================] - 3s 2ms/step\n",
      "Test MSE: 5618096.273775256\n",
      "Test RMSE: 2370.2523649972923\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_economy)\n",
    "X_test_scaled = scaler.transform(X_test_economy)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# param_grid = {\n",
    "#     'neurons1': [64, 128, 256],\n",
    "#     'neurons2': [32, 64, 128],\n",
    "#     'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search_result = grid_search.fit(X_train_scaled, y_train_economy)\n",
    "# best_params = grid_search_result.best_params_\n",
    "# print(best_params)\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(X_train_economy.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.fit(X_train_scaled, y_train_economy, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test_economy)\n",
    "print(f'Test MAE: {test_mae}')\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print MSE and RMSE\n",
    "mse = mean_squared_error(y_test_economy, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Test MSE: {mse}')\n",
    "print(f'Test RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25570ce2-3bb8-4558-8d84-a03f868ca2c2",
   "metadata": {},
   "source": [
    "## Bagging Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbccfbff-ba7b-407c-b952-b1d8ad582233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyper Parameters :\n",
      "{'max_features': 1.0, 'max_samples': 0.5, 'n_estimators': 15}\n",
      "Tuned Hyper Parameters :\n",
      "{'max_features': None, 'splitter': 'best'}\n",
      "MSE: 7295633.8596384935\n",
      "RMSE: 2701.043105846053\n",
      "MAE: 1145.898434661537\n"
     ]
    }
   ],
   "source": [
    "base_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Create a Bagging Regressor with Decision Trees as base estimators\n",
    "bagging_regressor = BaggingRegressor(base_regressor, n_estimators=10, random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(bagging_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "tree_bg = grid_search.fit(X_train, y_train)\n",
    "\n",
    "parameters = {\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'max_features' : [None, 8, 7, 6, 5],\n",
    "}\n",
    "\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "tree_cv = GridSearchCV(estimator=tree, param_grid=parameters, cv=20).fit(X_train, y_train)\n",
    "\n",
    "tree = DecisionTreeRegressor(**tree_cv.best_params_)\n",
    "bagging_regressor = BaggingRegressor(base_regressor,**tree_bg.best_params_, random_state=42)\n",
    "# Fit the Bagging Regressor on the training data\n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "y_pred = bagging_regressor.predict(X_test)\n",
    "\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "print(\"MSE: \" + str(mse))\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "print(\"MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf81b1-6762-49de-8024-7054ed8727ac",
   "metadata": {},
   "source": [
    "## Bagging Regression Tree for economy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d04abd5-8618-4f0e-a9be-8f2cf4ab738e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2028511.0323822298\n",
      "RMSE: 1424.2580638291047\n",
      "MAE: 627.2349961072184\n"
     ]
    }
   ],
   "source": [
    "base_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Create a Bagging Regressor with Decision Trees as base estimators\n",
    "bagging_regressor = BaggingRegressor(base_regressor, n_estimators=10, random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "# param_grid = {\n",
    "#     'n_estimators': [5, 10, 15],\n",
    "#     'max_samples': [0.5, 0.7, 1.0],\n",
    "#     'max_features': [0.5, 0.7, 1.0]\n",
    "# }\n",
    "\n",
    "# # Use GridSearchCV for hyperparameter tuning\n",
    "# grid_search = GridSearchCV(bagging_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# tree_bg = grid_search.fit(X_train_economy, y_train_economy)\n",
    "\n",
    "# parameters = {\n",
    "#     'splitter' : ['best', 'random'],\n",
    "#     'max_features' : [None, 8, 7, 6, 5],\n",
    "# }\n",
    "\n",
    "\n",
    "# tree = DecisionTreeRegressor()\n",
    "# tree_cv = GridSearchCV(estimator=tree, param_grid=parameters, cv=20).fit(X_train, y_train)\n",
    "\n",
    "tree = DecisionTreeRegressor(splitter='best',max_features=None)\n",
    "bagging_regressor = BaggingRegressor(base_regressor,n_estimators=15,max_samples=0.5,max_features=1.0, random_state=42)\n",
    "# Fit the Bagging Regressor on the training data\n",
    "bagging_regressor.fit(X_train_economy, y_train_economy)\n",
    "y_pred = bagging_regressor.predict(X_test_economy)\n",
    "\n",
    "mse = metrics.mean_squared_error(y_test_economy, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_test_economy, y_pred)\n",
    "print(\"MSE: \" + str(mse))\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "print(\"MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae98696-5b4e-4447-ae9a-ca5f7e0b0d63",
   "metadata": {},
   "source": [
    "## Bagging Regression Tree for business class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc7c68c9-5d75-4578-b3fc-e5f5e54d4c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 18615411.670074083\n",
      "RMSE: 4314.55810832049\n",
      "MAE: 2161.473036317215\n"
     ]
    }
   ],
   "source": [
    "base_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Create a Bagging Regressor with Decision Trees as base estimators\n",
    "bagging_regressor = BaggingRegressor(base_regressor, n_estimators=10, random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "# param_grid = {\n",
    "#     'n_estimators': [5, 10, 15],\n",
    "#     'max_samples': [0.5, 0.7, 1.0],\n",
    "#     'max_features': [0.5, 0.7, 1.0]\n",
    "# }\n",
    "\n",
    "# # Use GridSearchCV for hyperparameter tuning\n",
    "# grid_search = GridSearchCV(bagging_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# tree_bg = grid_search.fit(X_train_business, y_train_business)\n",
    "\n",
    "# parameters = {\n",
    "#     'splitter' : ['best', 'random'],\n",
    "#     'max_features' : [None, 8, 7, 6, 5],\n",
    "# }\n",
    "\n",
    "\n",
    "# tree = DecisionTreeRegressor()\n",
    "# tree_cv = GridSearchCV(estimator=tree, param_grid=parameters, cv=20).fit(X_train, y_train)\n",
    "\n",
    "tree = DecisionTreeRegressor(splitter='best',max_features=None)\n",
    "bagging_regressor = BaggingRegressor(base_regressor,n_estimators=15,max_samples=0.5,max_features=1.0, random_state=42)\n",
    "# Fit the Bagging Regressor on the training data\n",
    "bagging_regressor.fit(X_train_business, y_train_business)\n",
    "y_pred = bagging_regressor.predict(X_test_business)\n",
    "\n",
    "mse = metrics.mean_squared_error(y_test_business, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_test_business, y_pred)\n",
    "print(\"MSE: \" + str(mse))\n",
    "print(\"RMSE: \" + str(rmse))\n",
    "print(\"MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec18f6-bef3-4a8d-8eb1-5e5ccfe77c62",
   "metadata": {},
   "source": [
    "## Results for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6213b294-de87-4abe-860e-3f3486397a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Algorithm      MSE  RMSE  MAE\n",
      "      Linear Regression  8168976  2858 2065\n",
      "          Random Forest  7311588  2703 1070\n",
      "  Multilayer Perceptron 19842597  4454 2627\n",
      "Bagging Regression Tree  7295633  2701 1145\n",
      "         SVM Regression        0     0    0\n",
      "       Lasso Regression        0     0    0\n",
      "                XGBoost        0     0    0\n"
     ]
    }
   ],
   "source": [
    "data = { 'Algorithm': ['Linear Regression', 'Random Forest', 'Multilayer Perceptron', 'Bagging Regression Tree', 'SVM Regression', 'Lasso Regression', 'XGBoost'],\n",
    "         'MSE':[8168976, 7311588, 19842597, 7295633,0,0,0],\n",
    "         'RMSE':[2858, 2703, 4454, 2701,0,0,0],\n",
    "               'MAE':[2065, 1070, 2627, 1145,0,0,0]}\n",
    "dataframe = pandas.DataFrame(data)\n",
    "print(dataframe.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1668f23-3aef-4b02-afed-b8d2469818d1",
   "metadata": {},
   "source": [
    "## Results for business class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22c0353-3cd1-4654-ac94-83e5c385db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Algorithm      MSE  RMSE  MAE\n",
      "      Linear Regression 94337423  9712 7376\n",
      "          Random Forest 18960993  4354 2059\n",
      "  Multilayer Perceptron 85973699  9272 6884\n",
      "Bagging Regression Tree 18615411  4314 2161\n",
      "         SVM Regression        0     0    0\n",
      "       Lasso Regression        0     0    0\n",
      "                XGBoost        0     0    0\n"
     ]
    }
   ],
   "source": [
    "data = { 'Algorithm': ['Linear Regression', 'Random Forest', 'Multilayer Perceptron', 'Bagging Regression Tree', 'SVM Regression', 'Lasso Regression', 'XGBoost'],\n",
    "         'MSE':[94337423, 18960993, 85973699, 18615411,0,0,0],\n",
    "         'RMSE':[9712, 4354, 9272, 4314,0,0,0],\n",
    "         'MAE':[7376, 2059, 6884, 2161,0,0,0]}\n",
    "dataframe = pandas.DataFrame(data)\n",
    "print(dataframe.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d11426-d59a-4e76-9886-138702c85b9a",
   "metadata": {},
   "source": [
    "## Results for economy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c5549e9-278f-482f-b24d-0a7192d2da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Algorithm     MSE  RMSE  MAE\n",
      "      Linear Regression 8168976  2858 2065\n",
      "          Random Forest 1908115  1381  614\n",
      "  Multilayer Perceptron 5618096  2370 1623\n",
      "Bagging Regression Tree 2028511  1424  627\n",
      "         SVM Regression       0     0    0\n",
      "       Lasso Regression       0     0    0\n",
      "                XGBoost       0     0    0\n"
     ]
    }
   ],
   "source": [
    "data = { 'Algorithm': ['Linear Regression', 'Random Forest', 'Multilayer Perceptron', 'Bagging Regression Tree', 'SVM Regression', 'Lasso Regression', 'XGBoost'],\n",
    "         'MSE':[8168976, 1908115, 5618096, 2028511,0,0,0],\n",
    "         'RMSE':[2858, 1381, 2370, 1424,0,0,0],\n",
    "         'MAE':[2065, 614, 1623, 627,0,0,0]}\n",
    "dataframe = pandas.DataFrame(data)\n",
    "print(dataframe.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e20499-6cae-4276-85c1-b8681ab00c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
